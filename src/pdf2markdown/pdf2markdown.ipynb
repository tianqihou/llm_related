{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install qwen-vl-utils\n",
    "import os\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import logging\n",
    "import cv2\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "import fitz\n",
    "import concurrent.futures\n",
    "\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import numpy as np\n",
    "import fitz\n",
    "import logging\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from rapid_layout import RapidLayout, VisLayout\n",
    "\n",
    "\n",
    "VLM_PATH = \"/mnt/d/weights/Qwen2-VL-7B-Instruct-AWQ\"\n",
    "\n",
    "layout_engine = RapidLayout(conf_thres=0.5, model_type=\"pp_layout_cdla\")\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    VLM_PATH,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(VLM_PATH, trust_remote_code=True)\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    VLM_PATH,\n",
    "    min_pixels=min_pixels,\n",
    "    max_pixels=max_pixels,\n",
    ")\n",
    "\n",
    "# This Default Prompt Using Chinese and could be changed to other languages.\n",
    "DEFAULT_PROMPT = \"\"\"使用markdown语法，将图片中识别到的文字转换为markdown格式输出。你必须做到：\n",
    "1. 输出和使用识别到的图片的相同的语言，例如，识别到英语的字段，输出的内容必须是英语。\n",
    "2. 不要解释和输出无关的文字，直接输出图片中的内容。例如，严禁输出 “以下是我根据图片内容生成的markdown文本：”这样的例子，而是应该直接输出markdown。\n",
    "3. 内容不要包含在```markdown ```中、段落公式使用 $$ $$ 的形式、行内公式使用 $ $ 的形式、忽略掉长直线、忽略掉页码。\n",
    "再次强调，不要解释和输出无关的文字，直接输出图片中的内容。\n",
    "\"\"\"\n",
    "DEFAULT_RECT_PROMPT = \"\"\"图片中用带颜色的矩形框和名称(%s)标注出了一些区域。如果区域是表格或者图片，使用 ![]() 的形式插入到输出内容中，否则直接输出文字内容。\n",
    "\"\"\"\n",
    "DEFAULT_ROLE_PROMPT = \"\"\"你是一个PDF文档解析器，使用markdown和latex语法输出图片的内容。\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _parse_pdf_to_images(pdf_path: str, output_dir: str) -> List[Tuple[str, List[str]]]:\n",
    "    image_infos = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    for page_index, page in enumerate(pdf_document):\n",
    "        logging.info(f\"parse page: {page_index}\")\n",
    "        # 保存页面为图片\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(4, 4))\n",
    "        pix = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        boxes, scores, class_names, elapse = layout_engine(pix)\n",
    "        \n",
    "        rect_images = []\n",
    "        boxes_ = []\n",
    "        scores_ = []\n",
    "        class_names_ = []\n",
    "        rect_index = 0\n",
    "        for class_name, box, score in zip(class_names, boxes, scores):\n",
    "            if class_name == \"figure\" or class_name == \"table\":\n",
    "                rect_index += 1\n",
    "                name = f\"{page_index}_{rect_index}.png\"\n",
    "                sub_pix = pix.crop(box)\n",
    "                sub_pix.save(os.path.join(output_dir, name))\n",
    "                rect_images.append(name)\n",
    "\n",
    "                boxes_.append(box)\n",
    "                scores_.append(score)\n",
    "                class_name = f\"{page_index}_{rect_index}.png\"\n",
    "                class_names_.append(class_name)\n",
    "\n",
    "        page_image = os.path.join(output_dir, f\"{page_index}.png\")\n",
    "        pix = np.array(pix)\n",
    "        pix = cv2.cvtColor(pix, cv2.COLOR_RGB2BGR)\n",
    "        print(boxes_, scores_, class_names_)\n",
    "        ploted_img = VisLayout.draw_detections(pix, boxes_, scores_, class_names_)\n",
    "        if ploted_img is not None:\n",
    "            cv2.imwrite(page_image, ploted_img)\n",
    "        # ploted_img.save(page_image)\n",
    "        image_infos.append((page_image, rect_images))\n",
    "    pdf_document.close()\n",
    "    return image_infos\n",
    "\n",
    "def _gpt_parse_images(\n",
    "    image_infos: List[Tuple[str, List[str]]],\n",
    "    prompt_dict: Optional[Dict] = None,\n",
    "    output_dir: str = \"./\",\n",
    "    api_key: Optional[str] = None,\n",
    "    base_url: Optional[str] = None,\n",
    "    # model: str = 'gpt-4o',\n",
    "    verbose: bool = False,\n",
    "    gpt_worker: int = 1,\n",
    "    **args,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Parse images to markdown content.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(prompt_dict, dict) and \"prompt\" in prompt_dict:\n",
    "        prompt = prompt_dict[\"prompt\"]\n",
    "        logging.info(\"prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        prompt = DEFAULT_PROMPT\n",
    "        logging.info(\"prompt is not provided, using default prompt.\")\n",
    "    if isinstance(prompt_dict, dict) and \"rect_prompt\" in prompt_dict:\n",
    "        rect_prompt = prompt_dict[\"rect_prompt\"]\n",
    "        logging.info(\"rect_prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        rect_prompt = DEFAULT_RECT_PROMPT\n",
    "        logging.info(\"rect_prompt is not provided, using default prompt.\")\n",
    "    if isinstance(prompt_dict, dict) and \"role_prompt\" in prompt_dict:\n",
    "        role_prompt = prompt_dict[\"role_prompt\"]\n",
    "        logging.info(\"role_prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        role_prompt = DEFAULT_ROLE_PROMPT\n",
    "        logging.info(\"role_prompt is not provided, using default prompt.\")\n",
    "\n",
    "    def _process_page(index: int, image_info: Tuple[str, List[str]]) -> Tuple[int, str]:\n",
    "        logging.info(f\"gpt parse page: {index}\")\n",
    "\n",
    "        # agent = Agent(role=role_prompt, api_key=api_key, base_url=base_url, disable_python_run=True, model=model, **args)\n",
    "        page_image, rect_images = image_info\n",
    "        local_prompt = prompt\n",
    "        local_prompt = role_prompt+local_prompt\n",
    "        if rect_images:\n",
    "            local_prompt = local_prompt % (rect_prompt % \", \".join(rect_images))\n",
    "        else:\n",
    "            local_prompt = local_prompt % \"\"\n",
    "        # content = agent.run([local_prompt, {'image': page_image}], display=verbose)\n",
    "        messages = [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": DEFAULT_ROLE_PROMPT\n",
    "            # },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": page_image,\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": local_prompt},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        print(text)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "\n",
    "        # Inference: Generation of the output\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=2000, num_beams=1)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :]\n",
    "            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False,\n",
    "        )\n",
    "        return index, output_text\n",
    "\n",
    "    contents = [None] * len(image_infos)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=gpt_worker) as executor:\n",
    "        futures = [\n",
    "            executor.submit(_process_page, index, image_info)\n",
    "            for index, image_info in enumerate(image_infos)\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            index, content = future.result()\n",
    "            content = content[0]\n",
    "            print(content)\n",
    "\n",
    "            # 在某些情况下大模型还是会输出 ```markdown ```字符串\n",
    "            if \"```markdown\" in content:\n",
    "                content = content.replace(\"```markdown\\n\", \"\")\n",
    "                last_backticks_pos = content.rfind(\"```\")\n",
    "                if last_backticks_pos != -1:\n",
    "                    content = (\n",
    "                        content[:last_backticks_pos] + content[last_backticks_pos + 3 :]\n",
    "                    )\n",
    "\n",
    "            contents[index] = content\n",
    "\n",
    "    output_path = os.path.join(output_dir, \"output.md\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(contents))\n",
    "\n",
    "    return \"\\n\\n\".join(contents)\n",
    "\n",
    "\n",
    "def parse_pdf(\n",
    "    pdf_path: str,\n",
    "    base_output_dir=\"../../data/gen\",\n",
    "    prompt: Optional[Dict] = None,\n",
    "    api_key: Optional[str] = None,\n",
    "    base_url: Optional[str] = None,\n",
    "    model: str = \"gpt-4o\",\n",
    "    verbose: bool = False,\n",
    "    gpt_worker: int = 1,\n",
    "    **args,\n",
    ") -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Parse a PDF file to a markdown file.\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = os.path.join(base_output_dir, os.path.basename(pdf_path).split(\".\")[0])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image_infos = _parse_pdf_to_images(pdf_path, output_dir=output_dir)\n",
    "    print(image_infos)\n",
    "    content = _gpt_parse_images(\n",
    "        image_infos=image_infos,\n",
    "        output_dir=output_dir,\n",
    "        prompt_dict=prompt,\n",
    "        api_key=api_key,\n",
    "        base_url=base_url,\n",
    "        model=model,\n",
    "        verbose=verbose,\n",
    "        gpt_worker=gpt_worker,\n",
    "        **args,\n",
    "    )\n",
    "\n",
    "    all_rect_images = []\n",
    "    # remove all rect images\n",
    "    if not verbose:\n",
    "        for page_image, rect_images in image_infos:\n",
    "            if os.path.exists(page_image):\n",
    "                os.remove(page_image)\n",
    "            all_rect_images.extend(rect_images)\n",
    "    return content, all_rect_images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_PROMPT = \"\"\"使用markdown语法，将图片中识别到的文字转换为markdown格式输出。你必须做到：\n",
    "%s1. 不要解释和输出无关的文字，直接输出图片中的内容。例如，严禁输出 “以下是我根据图片内容生成的markdown文本：”这样的例子，而是应该直接输出markdown。\n",
    "2. 内容不要包含在```markdown ```中、段落公式使用 $$ $$ 的形式、行内公式使用 $ $ 的形式、忽略掉长直线、忽略掉页码。\n",
    "再次强调，不要解释和输出无关的文字，直接输出图片中的内容。\n",
    "\"\"\"\n",
    "DEFAULT_RECT_PROMPT = \"\"\"图片中用带颜色的矩形框和名称(%s)标注出了一些区域。这些区域要使用 ![]('名称') 的形式插入到markdown内容中，这很重要。\n",
    "\"\"\"\n",
    "DEFAULT_ROLE_PROMPT = \"\"\"你是一个PDF文档解析器，使用markdown和latex语法输出图片的内容。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = parse_pdf(\n",
    "    pdf_path=\"../../data/生命四元素.pdf\",\n",
    "    base_output_dir=\"../../data/gen\",\n",
    "    verbose=False,\n",
    "    gpt_worker=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用小钢炮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import logging\n",
    "import cv2\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "import fitz\n",
    "import concurrent.futures\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoProcessor\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from rapid_layout import RapidLayout, VisLayout\n",
    "\n",
    "\n",
    "\n",
    "VLM_PATH = \"/mnt/d/weights/MiniCPM-V-2_6-int4\"\n",
    "\n",
    "layout_engine = RapidLayout(conf_thres=0.5, model_type=\"pp_layout_cdla\")\n",
    "\n",
    "model = AutoModel.from_pretrained(VLM_PATH, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(VLM_PATH, trust_remote_code=True)\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    VLM_PATH,\n",
    "    trust_remote_code=True,\n",
    "    min_pixels=min_pixels,\n",
    "    max_pixels=max_pixels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _gpt_parse_images(\n",
    "    image_infos: List[Tuple[str, List[str]]],\n",
    "    prompt_dict: Optional[Dict] = None,\n",
    "    output_dir: str = \"./\",\n",
    "    api_key: Optional[str] = None,\n",
    "    base_url: Optional[str] = None,\n",
    "    # model: str = 'gpt-4o',\n",
    "    verbose: bool = False,\n",
    "    gpt_worker: int = 1,\n",
    "    **args,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Parse images to markdown content.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(prompt_dict, dict) and \"prompt\" in prompt_dict:\n",
    "        prompt = prompt_dict[\"prompt\"]\n",
    "        logging.info(\"prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        prompt = DEFAULT_PROMPT\n",
    "        logging.info(\"prompt is not provided, using default prompt.\")\n",
    "    if isinstance(prompt_dict, dict) and \"rect_prompt\" in prompt_dict:\n",
    "        rect_prompt = prompt_dict[\"rect_prompt\"]\n",
    "        logging.info(\"rect_prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        rect_prompt = DEFAULT_RECT_PROMPT\n",
    "        logging.info(\"rect_prompt is not provided, using default prompt.\")\n",
    "    if isinstance(prompt_dict, dict) and \"role_prompt\" in prompt_dict:\n",
    "        role_prompt = prompt_dict[\"role_prompt\"]\n",
    "        logging.info(\"role_prompt is provided, using user prompt.\")\n",
    "    else:\n",
    "        role_prompt = DEFAULT_ROLE_PROMPT\n",
    "        logging.info(\"role_prompt is not provided, using default prompt.\")\n",
    "\n",
    "    def _process_page(index: int, image_info: Tuple[str, List[str]]) -> Tuple[int, str]:\n",
    "        logging.info(f\"gpt parse page: {index}\")\n",
    "\n",
    "        # agent = Agent(role=role_prompt, api_key=api_key, base_url=base_url, disable_python_run=True, model=model, **args)\n",
    "        page_image, rect_images = image_info\n",
    "        local_prompt = role_prompt + prompt\n",
    "        if rect_images:\n",
    "            local_prompt = local_prompt % (rect_prompt % \", \".join(rect_images))\n",
    "        else:\n",
    "            local_prompt = local_prompt % \"\"\n",
    "\n",
    "        image = Image.open(page_image).convert('RGB')\n",
    "\n",
    "        msgs = [{'role': 'user', 'content': [image, local_prompt]}]\n",
    "\n",
    "        res = model.chat(\n",
    "            image=None,\n",
    "            msgs=msgs,\n",
    "            tokenizer=tokenizer,\n",
    "            processor=processor,\n",
    "            # system_prompt=role_prompt,\n",
    "            sampling=True,\n",
    "            temperature=0.7,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        generated_text = \"\"\n",
    "        for new_text in res:\n",
    "            generated_text += new_text\n",
    "            print(new_text, flush=True, end='')\n",
    "\n",
    "        return index, generated_text\n",
    "\n",
    "    contents = [None] * len(image_infos)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=gpt_worker) as executor:\n",
    "        futures = [\n",
    "            executor.submit(_process_page, index, image_info)\n",
    "            for index, image_info in enumerate(image_infos)\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            index, content = future.result()\n",
    "            print(content)\n",
    "\n",
    "            # 在某些情况下大模型还是会输出 ```markdown ```字符串\n",
    "            if \"```markdown\" in content:\n",
    "                content = content.replace(\"```markdown\\n\", \"\")\n",
    "                last_backticks_pos = content.rfind(\"```\")\n",
    "                if last_backticks_pos != -1:\n",
    "                    content = (\n",
    "                        content[:last_backticks_pos] + content[last_backticks_pos + 3 :]\n",
    "                    )\n",
    "\n",
    "            contents[index] = content\n",
    "\n",
    "    output_path = os.path.join(output_dir, \"output.md\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(contents))\n",
    "\n",
    "    return \"\\n\\n\".join(contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:34:33,468 - INFO - prompt is not provided, using default prompt.\n",
      "2024-09-10 18:34:33,469 - INFO - rect_prompt is not provided, using default prompt.\n",
      "2024-09-10 18:34:33,469 - INFO - role_prompt is not provided, using default prompt.\n",
      "2024-09-10 18:34:33,470 - INFO - gpt parse page: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Four Elements of Astrology, Psychology\n",
      "\n",
      "![](0_1.png)\n",
      "\n",
      "生命四元素  \n",
      "占星与心理学  \n",
      "\n",
      "史蒂芬·阿若优 著  \n",
      "胡因梦 译  \n",
      "\n",
      "占星心理学大师畅销全球的经典力作  \n",
      "\n",
      "云南出版集团公司# Four Elements of Astrology, Psychology\n",
      "\n",
      "![](0_1.png)\n",
      "\n",
      "生命四元素  \n",
      "占星与心理学  \n",
      "\n",
      "史蒂芬·阿若优 著  \n",
      "胡因梦 译  \n",
      "\n",
      "占星心理学大师畅销全球的经典力作  \n",
      "\n",
      "云南出版集团公司\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Four Elements of Astrology, Psychology\\n\\n![](0_1.png)\\n\\n生命四元素  \\n占星与心理学  \\n\\n史蒂芬·阿若优 著  \\n胡因梦 译  \\n\\n占星心理学大师畅销全球的经典力作  \\n\\n云南出版集团公司'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gpt_parse_images([image_infos[0]], output_dir=\"../../data/gen1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:05,925 - INFO - parse page: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 169.94206096,  191.13674955, 2555.84851203, 2867.47954901])] [0.7510790824890137] ['0_1.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:06,500 - INFO - parse page: 1\n",
      "2024-09-10 18:37:06,747 - INFO - parse page: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:07,053 - INFO - parse page: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:07,348 - INFO - parse page: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:07,645 - INFO - parse page: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:07,946 - INFO - parse page: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:08,234 - INFO - parse page: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:08,541 - INFO - parse page: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:08,822 - INFO - parse page: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:09,099 - INFO - parse page: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:09,427 - INFO - parse page: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 401.52155752, 2951.1392122 , 2595.89004202, 3811.43398382])] [0.9714148044586182] ['10_1.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:09,860 - INFO - parse page: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 434.74053057,  589.79211234, 2621.14796733, 3543.77794534])] [0.9796044230461121] ['11_1.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:10,273 - INFO - parse page: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 371.23547482, 1823.66235113, 2577.95901314, 3852.0138674 ])] [0.9791556596755981] ['12_1.png']\n",
      "[array([ 437.43804541,  566.85555348, 2639.36469945, 2296.20674073]), array([ 438.75370886, 2612.67350286, 2659.55175839, 3801.18270579])] [0.958814799785614, 0.9587647318840027] ['13_1.png', '13_2.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:10,725 - INFO - parse page: 14\n",
      "2024-09-10 18:37:11,136 - INFO - parse page: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 378.10205936,  570.82575883, 2559.93304288, 3585.65486196])] [0.9778209328651428] ['14_1.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:11,458 - INFO - parse page: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 401.69990228,  585.05546272, 2582.1932818 , 2139.04589959])] [0.9434552192687988] ['15_1.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:11,731 - INFO - parse page: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:12,029 - INFO - parse page: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:12,314 - INFO - parse page: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:12,622 - INFO - parse page: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:12,894 - INFO - parse page: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:13,163 - INFO - parse page: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:13,442 - INFO - parse page: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:13,728 - INFO - parse page: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:14,052 - INFO - parse page: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:14,382 - INFO - parse page: 26\n",
      "2024-09-10 18:37:14,680 - INFO - parse page: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:14,991 - INFO - parse page: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:15,263 - INFO - parse page: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:15,544 - INFO - parse page: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:15,817 - INFO - parse page: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:16,081 - INFO - parse page: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:16,343 - INFO - parse page: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:16,636 - INFO - parse page: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:16,950 - INFO - parse page: 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:17,250 - INFO - parse page: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:17,557 - INFO - parse page: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:17,859 - INFO - parse page: 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:18,176 - INFO - parse page: 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:18,472 - INFO - parse page: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:18,812 - INFO - parse page: 41\n",
      "2024-09-10 18:37:19,121 - INFO - parse page: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:19,348 - INFO - parse page: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:19,627 - INFO - parse page: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:19,928 - INFO - parse page: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:20,228 - INFO - parse page: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:20,523 - INFO - parse page: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:20,813 - INFO - parse page: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:21,145 - INFO - parse page: 49\n",
      "2024-09-10 18:37:21,443 - INFO - parse page: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:21,730 - INFO - parse page: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:22,017 - INFO - parse page: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:22,328 - INFO - parse page: 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:22,693 - INFO - parse page: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:23,033 - INFO - parse page: 55\n",
      "2024-09-10 18:37:23,317 - INFO - parse page: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:23,604 - INFO - parse page: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 18:37:23,899 - INFO - parse page: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "[] [] []\n",
      "[('../../data/gen/生命四元素/0.png', ['0_1.png']), ('../../data/gen/生命四元素/1.png', []), ('../../data/gen/生命四元素/2.png', []), ('../../data/gen/生命四元素/3.png', []), ('../../data/gen/生命四元素/4.png', []), ('../../data/gen/生命四元素/5.png', []), ('../../data/gen/生命四元素/6.png', []), ('../../data/gen/生命四元素/7.png', []), ('../../data/gen/生命四元素/8.png', []), ('../../data/gen/生命四元素/9.png', []), ('../../data/gen/生命四元素/10.png', ['10_1.png']), ('../../data/gen/生命四元素/11.png', ['11_1.png']), ('../../data/gen/生命四元素/12.png', ['12_1.png']), ('../../data/gen/生命四元素/13.png', ['13_1.png', '13_2.png']), ('../../data/gen/生命四元素/14.png', ['14_1.png']), ('../../data/gen/生命四元素/15.png', ['15_1.png']), ('../../data/gen/生命四元素/16.png', []), ('../../data/gen/生命四元素/17.png', []), ('../../data/gen/生命四元素/18.png', []), ('../../data/gen/生命四元素/19.png', []), ('../../data/gen/生命四元素/20.png', []), ('../../data/gen/生命四元素/21.png', []), ('../../data/gen/生命四元素/22.png', []), ('../../data/gen/生命四元素/23.png', []), ('../../data/gen/生命四元素/24.png', []), ('../../data/gen/生命四元素/25.png', []), ('../../data/gen/生命四元素/26.png', []), ('../../data/gen/生命四元素/27.png', []), ('../../data/gen/生命四元素/28.png', []), ('../../data/gen/生命四元素/29.png', []), ('../../data/gen/生命四元素/30.png', []), ('../../data/gen/生命四元素/31.png', []), ('../../data/gen/生命四元素/32.png', []), ('../../data/gen/生命四元素/33.png', []), ('../../data/gen/生命四元素/34.png', []), ('../../data/gen/生命四元素/35.png', []), ('../../data/gen/生命四元素/36.png', []), ('../../data/gen/生命四元素/37.png', []), ('../../data/gen/生命四元素/38.png', []), ('../../data/gen/生命四元素/39.png', []), ('../../data/gen/生命四元素/40.png', []), ('../../data/gen/生命四元素/41.png', []), ('../../data/gen/生命四元素/42.png', []), ('../../data/gen/生命四元素/43.png', []), ('../../data/gen/生命四元素/44.png', []), ('../../data/gen/生命四元素/45.png', []), ('../../data/gen/生命四元素/46.png', []), ('../../data/gen/生命四元素/47.png', []), ('../../data/gen/生命四元素/48.png', []), ('../../data/gen/生命四元素/49.png', []), ('../../data/gen/生命四元素/50.png', []), ('../../data/gen/生命四元素/51.png', []), ('../../data/gen/生命四元素/52.png', []), ('../../data/gen/生命四元素/53.png', []), ('../../data/gen/生命四元素/54.png', []), ('../../data/gen/生命四元素/55.png', []), ('../../data/gen/生命四元素/56.png', []), ('../../data/gen/生命四元素/57.png', []), ('../../data/gen/生命四元素/58.png', [])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_gpt_parse_images() got an unexpected keyword argument 'api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m DEFAULT_RECT_PROMPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m图片中用带颜色的矩形框和名称(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)标注出了一些区域。这些区域要使用 ![](\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m名称\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) 的形式插入到markdown内容中，这很重要。\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m DEFAULT_ROLE_PROMPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m你是一个PDF文档解析器，使用markdown和latex语法输出图片的内容。\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mparse_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/生命四元素.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/gen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 181\u001b[0m, in \u001b[0;36mparse_pdf\u001b[0;34m(pdf_path, base_output_dir, prompt, api_key, base_url, model, verbose, gpt_worker, **args)\u001b[0m\n\u001b[1;32m    179\u001b[0m image_infos \u001b[38;5;241m=\u001b[39m _parse_pdf_to_images(pdf_path, output_dir\u001b[38;5;241m=\u001b[39moutput_dir)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_infos)\n\u001b[0;32m--> 181\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43m_gpt_parse_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpt_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m all_rect_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# remove all rect images\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: _gpt_parse_images() got an unexpected keyword argument 'api_key'"
     ]
    }
   ],
   "source": [
    "DEFAULT_PROMPT = \"\"\"使用markdown语法，将图片中识别到的文字转换为markdown格式输出。你必须做到：\n",
    "%s1. 不要解释和输出无关的文字，直接输出图片中的内容。例如，严禁输出 “以下是我根据图片内容生成的markdown文本：”这样的例子，而是应该直接输出markdown。\n",
    "2. 内容不要包含在```markdown ```中、段落公式使用 $$ $$ 的形式、行内公式使用 $ $ 的形式、忽略掉长直线、忽略掉页码。\n",
    "再次强调，不要解释和输出无关的文字，直接输出图片中的内容。\n",
    "\"\"\"\n",
    "DEFAULT_RECT_PROMPT = \"\"\"图片中用带颜色的矩形框和名称(%s)标注出了一些区域。这些区域要使用 ![]('名称') 的形式插入到markdown内容中，这很重要。\n",
    "\"\"\"\n",
    "DEFAULT_ROLE_PROMPT = \"\"\"你是一个PDF文档解析器，使用markdown和latex语法输出图片的内容。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = parse_pdf(\n",
    "    pdf_path=\"../../data/生命四元素.pdf\",\n",
    "    base_output_dir=\"../../data/gen\",\n",
    "    verbose=False,\n",
    "    gpt_worker=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
